{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bc64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import spacy\n",
    "import numpy as np\n",
    "# Storing docs in binary format\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7db44613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"Data1.csv\", encoding='latin-1')\n",
    "df['Sentiment'] = ['negative' if x == 'negative' else 'positive_neutral' for x in df['Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82fd71b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive_neutral\n",
       "1       positive_neutral\n",
       "2               negative\n",
       "3       positive_neutral\n",
       "4       positive_neutral\n",
       "              ...       \n",
       "4841            negative\n",
       "4842    positive_neutral\n",
       "4843            negative\n",
       "4844            negative\n",
       "4845            negative\n",
       "Name: Sentiment, Length: 4846, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca09d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the dataset into train and test\n",
    "train = df.sample(frac = 0.8, random_state = 25)\n",
    "test = df.drop(train.index)\n",
    "nlp=spacy.load(\"en_core_web_md\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83edcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tuples'] = train.apply(lambda row: (row['Text'],row['Sentiment']), axis=1)\n",
    "train = train['tuples'].tolist()\n",
    "test['tuples'] = test.apply(lambda row: (row['Text'],row['Sentiment']), axis=1)\n",
    "test = test['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c18fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document(data):\n",
    "    text = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples = True):\n",
    "        if (label=='negative'):\n",
    "            doc.cats['negative'] = 1\n",
    "            doc.cats['positive_neutral'] = 0\n",
    "        else:\n",
    "            doc.cats['positive_neutral'] = 1\n",
    "            doc.cats['negative'] = 0\n",
    "        \n",
    "        text.append(doc)\n",
    "  \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f01294d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:09.989443\n"
     ]
    }
   ],
   "source": [
    "# Calculate the time for converting into binary document for train dataset\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "#passing the train dataset into function 'document'\n",
    "train_docs = document(train)\n",
    "\n",
    "#Creating binary document using DocBin function in spaCy\n",
    "doc_bin = DocBin(docs = train_docs)\n",
    "\n",
    "#Saving the binary document as train.spacy\n",
    "doc_bin.to_disk(\"train.spacy\")\n",
    "end_time = datetime.now()\n",
    "\n",
    "#Printing the time duration for train dataset\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7ab1e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:02.511299\n"
     ]
    }
   ],
   "source": [
    "# Calculate the time for converting into binary document for test dataset\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "#passing the test dataset into function 'document'\n",
    "test_docs = document(test)\n",
    "doc_bin = DocBin(docs = test_docs)\n",
    "doc_bin.to_disk(\"valid.spacy\")\n",
    "end_time = datetime.now()\n",
    "\n",
    "#Printing the time duration for test dataset\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04ed1fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: python -m spacy init fill-config [OPTIONS] BASE_PATH [OUTPUT_FILE]\n",
      "Try 'python -m spacy init fill-config --help' for help.\n",
      "\n",
      "Error: Invalid value for 'BASE_PATH': File 'base-config.cfg' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a4bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: output_updated\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'textcat_multilabel']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS TEXTC...  CATS_MACRO_F  SCORE \n",
      "---  ------  ------------  -------------  ------------  ------\n",
      "  0       0          0.00           0.28         45.57    0.46\n",
      "  1     200          0.00          17.09         81.52    0.82\n",
      "  3     400          0.00           8.80         84.95    0.85\n",
      "  4     600          0.00           4.45         81.34    0.81\n",
      "  6     800          0.00           2.42         82.30    0.82\n",
      "  8    1000          0.00           1.97         80.04    0.80\n",
      "  9    1200          0.00           1.17         80.01    0.80\n",
      " 11    1400          0.00           0.78         82.21    0.82\n",
      " 13    1600          0.00           0.82         81.96    0.82\n",
      " 14    1800          0.00           0.54         78.44    0.78\n",
      " 16    2000          0.00           0.63         80.18    0.80\n",
      "[+] Saved pipeline to output directory\n",
      "output_updated\\model-last\n",
      "Duration: 0:09:36.692620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-25 12:17:53,549] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "[2022-08-25 12:17:53,769] [INFO] Set up nlp object from config\n",
      "[2022-08-25 12:17:53,779] [DEBUG] Loading corpus from path: valid.spacy\n",
      "[2022-08-25 12:17:53,779] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2022-08-25 12:17:53,780] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2022-08-25 12:17:53,780] [INFO] Pipeline: ['tok2vec', 'textcat_multilabel']\n",
      "[2022-08-25 12:17:53,785] [INFO] Created vocabulary\n",
      "[2022-08-25 12:17:53,786] [INFO] Finished initializing nlp object\n",
      "[2022-08-25 12:17:56,090] [INFO] Initialized pipeline components: ['tok2vec', 'textcat_multilabel']\n",
      "[2022-08-25 12:17:56,099] [DEBUG] Loading corpus from path: valid.spacy\n",
      "[2022-08-25 12:17:56,100] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2022-08-25 12:17:56,101] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2022-08-25 12:17:56,116] [DEBUG] Removed existing output directory: output_updated\\model-best\n",
      "[2022-08-25 12:17:56,130] [DEBUG] Removed existing output directory: output_updated\\model-last\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "!python -m spacy train config.cfg --verbose  --output ./output_updated --paths.train train.spacy --paths.dev valid.spacy\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b090a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2022-08-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\mlflow\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spacy\n",
    "import spacy\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "print(\"Today's date:\", today)\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"Spacy Model\")\n",
    "\n",
    "# MLflow Tracking\n",
    "nlp = spacy.load('output_updated\\model-last')\n",
    "with mlflow.start_run(run_name=f'Spacy_{today}_workin'):\n",
    "    mlflow.set_tag('model_flavor', 'spacy')\n",
    "    mlflow.spacy.log_model(spacy_model=nlp, artifact_path='model')\n",
    "    mlflow.log_metric('accuracy',0.72)\n",
    "    my_run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "\n",
    "# MLflow Models\n",
    "model_uri = f'runs:/{my_run_id}/model'\n",
    "nlp2 = mlflow.spacy.load_model(model_uri=model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d84a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_neutral': 0.005847441032528877, 'negative': 0.987448513507843}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp2(\"Barclays lost money\")\n",
    "doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42c13ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"predictions\": {\"positive_neutral\": 0.9982155561447144, \"negative\": 0.0021095010451972485}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   149  100    94  100    55   5875   3437 --:--:-- --:--:-- --:--:--  9312\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"text\\\"],\\\"data\\\":[\\\"There is a negative new\\\"]}\" http://127.0.0.1:1234/invocations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
